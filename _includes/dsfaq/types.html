That's a poorly defined question, Gavin. We can classify ML systems in a few ways: by the sort of data they use; by the abstract approach their algorithm takes; by the structure of the task they're solving, or by the literal task ("speech recognisers" or "car drivers").<br><br>

<div class="accordion">
	<h3>By nature of inputs</h3>
	<div class="accordion">
		<h3>Unsupervised learning</h3>
			<div class="accordion">
				<h3>Clustering: take unlabelled inputs, give discrete outputs.</h3>
				<div><ul>
					<li>Centroid-based:</li>
					<li>Density-based:</li>
					<li>Distribution-based:</li>
					<li>Hierarchical:</li>
				</ul>
				</div>
			</div>
		
		<h3>Supervised learning</h3>
		<div>
			<ul><li>Classification: labelled inputs, discrete output</li></ul>
		</div>
		<h3>Reinforcement learning</h3>
		<div>
			Kind of in-between.
		</div>
	</div>
	<h3>By nature of output</h3>
	<div>
		<ul>
			<li>Classification: gives a discrete output over a set of groups<br>
			<b>e.g.</b>: logistic regression, linear SVM, na√Øve Bayes, classification tree, collaborative filtering: KNN, alternating least squares (ALS), non-negative matrix factorization (NMF)</li><br>

			<li>Regression: <br>
			<b>e.g.</b>: generalized linear models (GLMs), regression tree</li><br>

			<li>Clustering, discrete output for unknown groups<br>
			<b>e.g.</b>: k-means, DBSCAN.</li><br>

			<li>Density estimation, output the distribution of inputs.</li><br>

			<li>Dimensionality reduction: Singular value decomposition, Principal Components analysis</li><br>
			
			<li>optimization: stochastic gradient descent, L-BFGS</li>
		</ul>
	</div>
</div>


