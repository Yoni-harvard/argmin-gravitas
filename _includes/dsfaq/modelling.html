{%	assign Induct = "https://en.wikipedia.org/wiki/Problem_of_induction"		%}



<h3>What's a model?</h3>
<div>
	A mathematical structure that approximates a part of the world. (Hopefully the part that caused your data.) <br><br>

	Models are <i>intentionally</i> fake and smooth toys. This is because adding too much detail takes too much time and computing to be useful, and makes it impossible to make general claims, and actually prevents you from understanding the thing at hand. ("Can't see the wood for the trees.")<br><br> 

	A model's abstraction allows us to see the unity of seemingly unrelated problems (for instance, magnetisation, the changes in states of matter, and riots are all explained by just one kind of model, <a href="https://en.wikipedia.org/wiki/Critical_point_(thermodynamics)">criticality theory</a>). And many phenomena fall under one "power law" distribution and can be said to share a deep structure.

	<br><br>Writing a model out in equations or programs allows us to make it completely clear and precise (and thus allows us to computerise it). A model summarises, simplifies, unifies, and guides. Occasionally it surpasses.<br><br>

	A <i>statistical</i> model is one which admits that it's not going to get the exact right answer every time (or any time) but which offers a good approximation in an uncertain world, given always-flawed data.
</div>


<h3>Why does data leave us uncertain?</h3>
<div>Because<br>
	<ul>
		<li>it is always incomplete (small samples, few features, physical limits)</li>
		<li>it is usually an indirect reflection of the thing of interest. (proxies, latency)</li>
		<li>it is noisy (measurement error, data corruption, unknown processes)</li>
		<li>it always has some risk of being fabricated.</li>
		<li>it is often ambiguous.</li>
		<li>of the fundamental <a href="{{Induct}}">nature of inductive thought</a>: you can never be <i>sure</i> via sampling.</li>
	</ul>
</div>


<h3>What can modelling do?</h3>
<div>
	<ul>
		<li>summarise data</li>
		<li>predict new data</li>
		<li>simulate reality</li>
	</ul>
	Note that these three aims are actually super-sets of each other:<br><br>

	to predict new data is to use a model to summarise future data. (Since a model is also a compressed description of a dataset.) To simulate reality requires you to infer actual structure and true parameters: to infer these is to <i>predict</i> that future data will confirm your estimates of them, and the inference is also a prediction that repeat experiments will find the same parameters, if you factor out noise.
</div>


<h3>Why is my model wrong?</h3>
<div>Hoo boy.<br><br>

	<div class="accordion">
	<h3>Model error</h3>
	<div>
		<ul><li>Model is approximation</li>
		<li>Best fit sucks</li>
		<li>Black swan</li>
		</ul>
	</div>
	
	<h3>Parameter error</h3>
	<div>
		<ul>
			<li>Concept drift</li>
			<li>Bad estimate</li>
			<ul>
				<li>Sampling error</li>
				<li>Systematic measurement error</li>
				<li>Numerical errors (discretization, truncation, round-off)</li>
			</ul>
		</ul>
	</div>

	<h3>Stochastic error</h3>
	<div>
		Everything's fine, you just got unlucky.
	</div>
	</div>
</div>


<h3>My model used to be right; why is it wrong now?</h3>
<div>
	<ul>
		<li>It was overfitted to an imperfectly representative training set.</li>
		<li>The population has changed ("Concept drift")</li>
		<li>Your analysis environment has changed ("Data drift")</li>
	</ul><br>
	<div class="accordion">
		<h3>What causes data drift?</h3>
		<div>
			<ul><li>Structural drift: the source schema is changed</li>
			<li>Semantic drift: the data is constant but its meaning changes.</li>
			<li>Infrastructure drift: breaking change in an update to some part of pipeline.</li>
			</ul>
		</div>
	</div>
</div>
