
<div class="footnotes">
<ol>
    <!-- 1 -->
     <li class="footnote" id="fn:1">
        Though it maybe won't remain an art <a href="{{otto}}">for long.</a>
     </li>

    <li class="footnote" id="fn:2">
    	That <i>Programmer Competency Matrix</i> is aggressively written: it is exasperated with poor job applicants. But when I was a clueless beginner, I found it helpful for someone to just <i>tell</i> me what exactly I was missing, even if that was a long list and 10 years' work to go.
    </li>

     <li class="footnote" id="fn:3">
     	This quotation isn't very relevant, I just think it's bad ass. It is from Judea Pearl's <a href="{{pearl}}">acceptance speech for the Lakatos Award</a>. <br><br>
     </li>
     
    <li class="footnote" id="fn:4">
        It's easy to say the reason is just pay, but that's circular: data scientists are paid more <i>in prospect</i>, because of the buzz around them, before they get anything done in a given organisation.<br><br> 

        I suppose the real productivity gains of e.g. Hammerbacher and LeCun could have caused the hype...
    </li> 

    <li class="footnote" id="fn:5">
        "70%" :
        <br><br><i>Estimate quality</i>: OK, a <a href='/metrics#spiegel-quality/'>Spiegelhalter (2*)</a>. 
        <br><i>Sample size</i>: 250. Not randomised.        
        <br><i>Source</i>: O'Reilly.
        <br><i>Importance to argument</i>: High.<br>&nbsp;
    </li>
    

    <li class="footnote" id="fn:6">
        The other very distinct job is of course "data engineer". But those are already distinguished properly in the job market, for the obvious reason that your cluster will crash and burn if you hire the wrong one of them. 
    </li>
    
    <li class="footnote" id="fn:7">
        <a href="{{leemis}}">Man this is a great site</a>.
    </li>

    <li class="footnote" id="fn:8">
        New methods? Newer than what?<br><br>

        Newer than pre-computer and tiny-sample statistical inference theory. You can get a sense for how new ML is from <a href="{{bishopp}}">Bishop (2006)</a>. That book only mentions very important papers. And, in fact, <a href="{{bishBib}}">summarising its bibliography</a> gets us a median year of 1995 and a mode year 1999. So even ignoring the disproportionately important last ten years, it is a very young field. 
    </li>
    
    
    <li class="footnote" id="fn:9">
     The hyperparameters of a data scientist are mathematical rigour, coding ability, misanthropy and pay. 
    </li>

    <li class="footnote" id="fn:10">
        Kaggle is just feature play and modelling. (So, if this Process defines the job 'data scientist' well, then Kaggle is just a ML platform, not a data science platform, as labelled.)<br><br>
    </li>
    

    <li class="footnote" id="fn:133">
        Also called <i>statistical error</i> or <i>random error</i>, but those names are vague to me. I suppose they get called statistical errors because you can use pure stats to detect and control for them, unlike systematic error.
    </li>

    <li class="footnote" id="fn:134">
        Model error and parameter error seem like they could be unified: if a model error is just a sufficiency large (number of) parameter errors. Making bad assumptions about e.g. auto-correlation between your features seems like just parameter error, while using the wrong distribution is model error.<br><br>

        This hinges on whether models are just big collections of parameters, I guess.
    </li>

    <li class="footnote" id="fn:200">
        which billions do not even count the main value Linux creates, externalities: induced demand for other software, and coerced quality from MS and Apple.
    </li>

    <li class="footnote" id="fn:201">
        Writing analysis scripts is much less heavy than real development, where it'd be absurdly expensive to '<a href="{{roro}}">roll your own</a>' very often.
    </li>

     <li class="footnote" id="fn:301">
        Following recent convention, she calls the systems 'algorithms'. But it isn't the inaccurate or static abstract program that does the harm, but credulous lack of validation of the program. They only do harm when they are allowed to make or guide decisions.<br><br>

        See also "recommender systems", "info filtering systems", "decision-making systems", "<a href="{{scor}}">credit scoring</a>".
    </li>

    <li class="footnote" id="fn:401">
        Currently called feature extraction, ambiguously IMO.  
    </li>

    <li class="footnote" id="fn:402">
        If you care, you can add further dimensions: <i>redundant</i>, <i>transformable</i>, <i>measurable</i> for a less readable 64 classes.    
    </li>

    <li class="footnote" id="fn:403">
        Please don't use "sample" to mean a single data point; it serves us well as "a collection of data points".
    </li>

    <li class="footnote" id="fn:404">
        Though of course even <i>using</i> a fitted linear regression model is algorithmic: take the given value <i>x</i>, multiply by its coefficients, add the intercept, return <i>prediction</i>.
    </li>

    <li class="footnote" id="fn:405">
        This is Pedro Domingos' stark and good account, but it is classic: Tom Mitchell's 20 year old classic explains things the same way.
    </li>
    
</ol>
</div>