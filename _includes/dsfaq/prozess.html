{%	assign delug = "https://www.emc.com/leadership/digital-universe/2014iview/executive-summary.htm"		%}
{%	assign backprop = "https://en.wikipedia.org/wiki/Backpropagation#History"		%}
{%	assign HN1 = "https://news.ycombinator.com/item?id=13232883"		%}
{%	assign HN2 = "https://news.ycombinator.com/item?id=13421672"		%}
{%	assign Sex = "http://uk.businessinsider.com/how-much-money-you-earn-in-the-sexiest-job-of-the-21st-century-2016-2"		%}
{%	assign oreilly = "http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf" 	%}
{%	assign AB = "https://en.wikipedia.org/wiki/A/B_testing"		%}


<h3>Is it a bullshit fad?</h3>
<div>
	Not exactly. All, and I mean <i>all</i> of its insights come straight out of academic statistics and computer science, and hacker lore. But just because something is made of other things doesn't mean it isn't real, or that it can't be a valuable permutation.<br><br>

	(I grant you that only half of the excitement is due to these methods, the other half being a truckful of <a href="{{Sex}}">marketing hype</a>.)<br><br>

	"Data science" is a silly name for a few reasons: because all statisticians apply scientific methods to data, and have done for a hundred years; because all programming is programming on data; because the actual job has <i>much</i> more data munging and rote scripting in it than it has <a href="{{AB}}">experimental science</a>.<br><br> 
</div>


<h3>Why now?</h3>
<div>
	<ol>
		<li>The underlying cause of most of it is the <a href="{{delug}}">data deluge</a> - we collect millions of times more data, basically for free.<br>

		<ul><li>Distributed computing, because the dataset doesn't fit in one computer's RAM.</li>
			<li>Sudden great performance, because it turns out that scaling your sample size gives a qualitative change for some domains (“Unreasonable Effectiveness of Data”). Same algorithms <a href="{{backprop}}">as the 80s</a> sometimes!</li>
			<li>With processing power comes a market in data: unprecedented aggregations. Huge potential value in scraping and extracting unstructured sources. Very large market in data. Acxiom is a $1bn company, for just one example; though Google is probably the pre-eminent example.</li>
		    <li>Data products (FitBit; restaurants, friends, jobs; credit ratings; health)</li>
		</ul><br>
		(And <a href="https://en.wikipedia.org/wiki/Data_exhaust">the web and IoT</a> are the cause of that.)</li><br>
		
		<li>Unsupervised machine learning allows for cheap use of the much greater volume of data which isn't annotated with a neat output label (and so can't be used for supervised training).</li><br>
		
		<li>Cognitive automation: we have recently been able to automate high-level things which used to require skilled humans: trading decisions, media recommendations, fine art, maybe even hypothesis generation: i.e. creativity!</li><br>

		<li>Demand for real-time summary of these new datasets means a sudden investment in stream processing algorithms and frameworks (which were previously not a very efficient use of industrial computer scientists).</li>
	</ol>
</div>


<h3>A Strange Loop</h3>
<div><br>
	We can define a data scientist in a black-box manner, as follows:<br><br>
		<ul>
			<li><i>learner</i>: an inductive program that takes in example data and outputs a model.</li>
			<li><i>model</i>: a static program that takes examples and outputs predictions. </li>
			<li><i>data scientist</i>: a pretentious <a href="http://petrl.org">inductive program</a> that takes in data and a vague problem, and outputs a learner and some good hyperparameters. <a href="#fn:9" id="fnref:9">9</a></li>
		</ul><br>
 			
 		That ^ is vague; here's a breakdown of the actual tasks involved:<br>
</div>


<h3>The Data Science Process</h3>
<div>
	<div class="accordion">
		<h3>1. Domain analysis</h3>	
		<div><i>What does this vague request really mean?</i><br><br>
		<ul>
		<li>Metric choice - How will we judge success?</li>
		<li>Tool choice</li>
		<li>Abstraction from business to data</li>
		<li>Abstraction from data to learner and models</li>
		<li>Output type. Real-time?</li>
		</ul>

		</div>

		<h3>2. Data collection</h3>	
		<div>	What evidence exists? What can I use?
		</div>

		<h3>3. Data cleaning</h3>	
		<div>How to handle flawed data?<br><br>

		This isn't a deep skill so much as a bag of tricks, like:<br>
		<ul>
			<li>The outliers dilemma</li>
			<li>Missing data imputation</li>
			<li>Bad data</li>
			<li>Encoding categoricals</li>
			<li>Identifying measurement bias</li>
			<li>Clever anonymisation in a world where everyone can be sniffed out.</li>
		</ul><br>

		See also data wrangling and <i>munging</i>.
		</div>

		<h3>4. Exploratory analysis</h3>	
		<div>	What is the data like? What jumps out?<br><br>
			<ul>
			<li>location (Inspect the distribution of target, ) </li>
			<li>spread (box plot, scatter plot, check for outliers)</li>
			<li>association (Pairwise distribution plots; What correlates with what?)</li>
			<li>Classification: plot the data with label-coloured points</li>
			</ul>
		</div>

		<h3>5. Feature engineering</h3>	
		<div>	<i>Which parts are useful?</i><br><br>
			
				{%	include dsfaq/feats.html	%}

			<br><br>

			This and 6. are the Kaggle bit. (So if this Process defines the job well, then Kaggle is a ML platform, not a data science platform.)<br><br>
		</div>

		<h3>6. Modelling</h3>	
		<div>	What structure will answer the question?<br><br>

		

		<ul>
			<li>Parameter tuning </li>
			<li>Ensemble construction</li>
			<li>Model selection </li>
			<li>Identify constraints</li><br>

			<li>Training </li>
			<li>Testing </li>
			<li>Validation </li>
			<li>Interpretation</li>

			<li>Evaluation - How good is this model? Under conditions?</li>
			Experiment design to make causal sense.
		</ul>
		</div>

		<h3>7. Deployment</h3>	
		<div>	How will this be used? Who will use it?<br><br>

		Create business rules 
		</div>

		<h3>8. Communication</h3>	
		<div>	What result?	
		</div>
	</div>
</div>


<h3>Skillset (for unicorns)</h3>
<div>Hard to beat the exhaustive list in <a href="{{oreilly}}">Harris et al</a> (2013). (Though it covers the things you'd expect a whole data science <i>team</i> to have: )<br><br>
	
	<ul>
		<li>Classical statistics (general linear model, ANOVA)</li>
		<li>Bayesian statistics (MCMC, BUGS)</li>
		<li>Simulation (discrete, agent-based, continuous)</li>
		<li>Spatial statistics (geographic covariates, GIS)</li>
		<li>Temporal statistics (forecasting, time-series analysis)</li>
		<li>Surveys and Marketing (multinomial modeling)</li><br>
		<li>Visualization (statistical graphics, mapping, web-based data‐viz)</li><br>

		<li>Distributed data (Hadoop, MapReduce)</li>
		<li>Structured data (SQL, JSON, XML)</li>
		<li>Unstructured data (noSQL, text mining)</li>
		<li>Data manipulation (regexes, R, SAS, web scraping)</li>
		<li>Systems administration (*nix, DBA, cloud tech.)</li>
		<li>Frontend programming (JavaScript, HTML, CSS)</li>
		<li>Backend programming (Java/Rails/Objective C)</li><br>

		<li>Algorithms (computational complexity, CS theory)</li>
		<li>Graphical models (social networks, Bayes networks)</li>
		<li>Machine learning (decision trees, neural nets, SVM, clustering)</li>
		<li>Analysis (linear algebra, real analysis, calculus)</li>
		<li>Optimization (linear, integer, convex, global)</li>
		<li>Science (experimental design, technical writing)</li><br>

		<li>Business (management, business development, budgeting)</li>
		<li>Product development (design, project management)</li><br>
	</ul>
</div>


<h3>Predecessors</h3>
<div>
	Similar roles have been played in the past by jobs like <i>expert system designer, decision support developer, knowledge discovery engineer, predictive analytics guy, business intelligence analyst, data miner, and big data engineer</i>, with varying levels of rigour and bullshit. The <i>quant developer</i>, in finance, is basically the same thing but with far less variance in skill level.<br><br>
	A more honest name for data scientist would be <i>analytics developer</i>... but hey we all got to make a living. The best you can say for us is, at least we don't claim that our poky little <a href="{{logReg}}">logistic regressor</a> is <a href="{{AIAI}}">An Artificial Intelligence</a>. (...)<br><br>

	Data analysis is an <i>art</i>, in <a href="{{Knuth}}">Knuth's sense</a>:<br><br>
	<blockquote>
		Science is everything we understand well enough to explain to a computer. Art is everything else we do.
	</blockquote>
	and thus so is data science. <a href="#fn:1" id="fnref:1">1</a> But it isn't cool to call yourself a data analyst, for some reason. <br><br><br>
</div>

<h3>Data science to define data science</h3>
<div>By surveying people with the job title "data scientist" and then clustering the data, <a href="{{oreilly}}">Harris et al.</a> split "data scientist" into four real jobs:<br><br>

	<ul>
		<li><i>Data researcher</i>: A postgrad statistician. Writes new algorithms, builds proof-of-concept ensembles, writes analysis libraries, disseminates. </li><br>
		<li><i>Data developer</i>: Machine learning engineer. Application builder. </li><br>
		<li><i>Data businessperson</i>: A knowledgeable interface between technical and non-technical people. Doesn’t code: steers modelling approach.</li><br>
		<li><i>Data creative</i>: Bit of everything. Heavy on visualisations? <a href="#fn:6" id="fnref:6">6</a></li>
	</ul>
	<br>

	Many, many articles act as if all DS jobs were data researcher jobs; this is the root of the <a href="{{HN1}}">constant</a> <a href="{{HN2}}">HN catfighting</a> about whether you need to know e.g. postgrad linear algebra <i>before starting</i>, let alone before applying.<br><br>

	Answer: data researchers obviously need to; the others, not so much. The <i>ineliminable</i> need is for decent coding skills. Maybe people take that need as too obvious to mention, but I've seen actual DS job applications which fail to mention programming once.<br><br>

	<div class="accordion">
		<h3>Alternative partition</h3>
		<div>
			You can also split data scientists by how well they understand the detail. This is surprisingly easy to operationalise:<br>
			<br><ol>
			<li>Can use libraries to build models</li>
			<li>Can implement the algorithms themselves</li>
			<li>Can invent new algorithms</li>
			</ol><br>

			I <i>bet</i> this ordering correlates with the performance of the models they build (r^2 > 0.4). But Kaggle don't have a financial interest in studying this.
		</div>
	</div>
</div>



<h3>Do I need a Master's degree to get a data science job?</h3>
<div>
	<a href="http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf">The 2013 O'Reilly survey of self-described data scientists</a> found 70% of respondents holding a Master's. <a href="#fn:5" id="fnref:5">5</a> Unless you are highly skilled already, or unless your target company are enlightened, you likely will. <br><br>

	You should be able to start as an analyst and work up though.
</div>
