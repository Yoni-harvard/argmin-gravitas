* No good evidence that taking a "<span class="b">power pose</span>" lowers cortisol, raises testosterone, risk tolerance.<br><br> 
> That a person can, by assuming two simple 1-min poses, embody power and instantly become more powerful has real-world,
actionable implications.

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
After the initial backlash, it focussed on subjective effect, a claim about "<a href="{{cuddy2}}">increased feelings of power</a>". Even then: <a href="{{crede}}">weak evidence</a> for decreased "feelings of power" from contractive posture only. My reanalysis is <a href="{{myanalysis}}">here</a>.<br>
<div class="accordion">
	<h3>Stats</h3>
	<div>
		<ul>
	<li><span class="b">Original paper</span>: '<a href="{{cuddy}}">Power Posing : Brief Nonverbal Displays Affect Neuroendocrine Levels and Risk Tolerance</a>', Cuddy, Carney & Yap 2010, n=42 mixed sexes.<br><br>
		<a href="{{fosseDiss}}">Many</a>, <a href="{{gelcud}}">many errors</a>. <a href="{{carney}}">Disowned</a> by one of its authors. Thanks to a reanalysis by someone else, <a href="{{fosse}}">we actually have the data</a>.
		<br>(&#126;1100 citations; 56m views on TED).</li><br>
	<li><span class="b">Critiques</span>: <a href="{{ranehill}}">Ranehill 2015</a>, n=200 (not an exact replication); <br>
		<a href="{{garrison}}">Garrison 2016</a>, n=305; <br>
		<a href="{{simonsohn}}">Simmons and Simonsohn 2016</a>, p-curve check of 33 studies; <br>
		<a href="{{ronay}}">Ronay 2017</a>, n=108; <br>
		<a href="{{peerj}}">Metzler 2019</a>, n=82 men. <br>
		<a href="{{crede2017}}">Crede 2017</a>, <a href="{{crede}}">Crede 2018</a>: multiverse analysis shows that the original result is heavily dependent on posthoc analysis choices.
		<!--  -->
		<br>(total citations: &#126;400)</li><br>
		<!--  -->
	<li><span class="b">Original effect sizes</span>: <br>
		h = 0.61 in risk-taking,<br> 
		d = minus 0.30 for cortisol, <br>  
		d=0.35 for testosterone <br>
		d=0.79 for feelings of power 
	</li><br>
	<li><span class="b">Replication effect size</span>: 
		risk-taking d = [−0.176], <br>
		testosterone d = [−0.2, −0.19, 0.121], <br>
		cortisol d = [−0.157, 0.22, 0.028, 0.034]<br> 
		most CIs overlapping 0
	</li>
	</ul>
	</div>
</div><br>

* Weak evidence for <span class="b">facial-feedback</span> (that smiling causes good mood and pouting bad mood).<br>
<div class="accordion">
	<h3>Stats</h3>
	<div>
		<ul>
	<li><span class="b">Original paper</span>: '<a href="{{strack}}">Inhibiting and Facilitating Conditions of the Human Smile: A Nonobtrusive Test of the Facial Feedback Hypothesis</a>' by Strack, Martin, Stepper 1988. n=92 twice.
		<br>(&#126;2200 citations).</li><br>
	<li><span class="b">Critiques</span>: 17 replications, <a href="{{wagen}}">Wagenmakers et al 2016</a>, <br>(total citations: &#126;220), <a href="{{schimm}}">Schimmack 2017</a></li><br>
	<li><span class="b">Original effect size</span>: d = 0.43 (0.82 out of 9)</li><br>
	<li><span class="b">Replication effect size</span>: 0.03 out of 9, CI overlapping 0.</li><br><br>

	<a href="{{cole}}">A meta-analysis of 98 studies</a> finds <i>d</i>= 0.2 [0.14, 0.26] with an absurdly low p value, and doesn't find publication bias. But this latter point simply can't be right. Given d = 0.2 and the convention of targeting 80% power to detect a real phenomenon, you would need very high sample sizes, n > 500. And almost all of the included studies are N < 100. <a href="{{schimm}}">Schimmack</a> finds strong evidence of publication bias on a subset of these papers, using a proper power analysis.<br><br> 

	98 pieces of very weak evidence cannot sum to strong evidence, whatever the p-value says. (<a href="{{colet}}">The author agrees</a>.)
	</ul>
	</div>
</div><br>


* <a href="{{halstead}}">Reason to be cautious</a> about <span class="b">mindfulness</span> for mental health. Most studies are low quality and use inconsistent designs, there's higher heterogeneity than other mental health treatments, and there's <a href="{{coron}}">strong reason</a> to suspect reporting bias. None of the 36 meta-analyses before 2016 mentioned publication bias. The hammer may fall.<br>
<div class="accordion">
	<h3>Stats</h3>
	<div>
		<ul>
	<li><span class="b">Critiques</span>: <a href="{{coronado}}">Coronado-Montoya 2016</a></li><br>
	<li><span class="b">Original effect size</span>: prima facie, <a href="{{jama}}">d=0.3</a> for anxiety or depression</li><br>
	<li><span class="b">Replication effect size</span>: Not yet.</li><br>
	</ul>
	</div>
</div><br>

* <a href="{{blue}}">No good evidence</a> for <span class="b">Blue Monday</span>, that the third week in January is the peak of depression or low affect 'as measured by a simple mathematical formula developed on behalf of Sky Travel'. You'd need a huge sample size, in the thousands, to detect the effect reliably and this has never been done.<br>

<br>