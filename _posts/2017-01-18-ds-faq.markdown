---
layout: 	math_post
title:  	"Elements of data science work"
baselink:	/data-science-faq
permalink:	/data-science-faw/
date:   	2017-02-01  <!--site.time-->
author:		Gavin	

published: 	false

visible:	1
simple:		true
technical:	true

summary:		Questions I wish I had known to ask before getting into data science.
confidence:		80%. I am still jejune.
categories:		data science
---

(Alright, alright, a few of these are infrequently asked. But you should have asked them.)

This post is inspired by [this][Snot] detailed list of concepts and skills that separate a freshman programmer from a lead engineer. (It is aggressively written, but when I was a clueless beginner, I found the detail and disdain invigorating.)




<div class="accordion">
	<h3>What's the best algorithm?</h3>
	<div>
	There is a proof that there is no such thing.<br><br>
	Currently, the most competitive algorithm over a range of well-defined problems is gradient boosting.
	</div>
	<h3>What can modelling do?</h3>
	<div>
	<ul>
	<li>summarise data</li>
	<li>predict new data</li>
	<li>simulate reality</li>
	</ul>
	<br>Note that these tasks are actually supersets: to predict new data is to summarise future data. To infer is to predict that these are the true parameters, and that repeat experiments (of the same quality) will find the same parameters (modulo noise). 
	</div>
	<h3>What sorts of machine learning are there?</h3>
	<div>
	<div class="accordion">
	<h3>Unsupervised learning</h3>
	<div>
	<div class="accordion">
	<h3>Clustering: unlabelled inputs, discrete output.</h3>
	<div>Centroid-based:
	Density-based:
	Distribution-based:
	Hierarchical:</div>
	</div>
	</div>
	<h3>Supervised learning</h3>
	<div>
	Classification: labelled inputs, discrete output
	</div>
	</div>
	</div>
	<h3>What is it that machines learn?</h3>
	<div>Not "knowledge" or "tasks"; instances of computational structures:
		<ul>
		<li>Functions</li>
		<li>Rulesets (ILP)</li>
		<li>State machines</li>
		<li>Grammars</li>
		<li>Problem solvers</li>
		</ul>
	</div>
	
	<h3>Why is my model wrong?</h3>
	<div class="accordion">
		<h3>Model error</h3>
		<div>
			<ul><li>Model is approximation</li>
			<li>Best fit sucks</li>
			<li>Black swan</li>
			</ul>
		</div>
		
		<h3>Parameter error</h3>
		<div>
			<ul>
			<li>Concept drift</li>
			<li>Bad estimate</li>
			<ul>
				<li>Sampling error</li>
				<li>Systematic measurement error</li>
				<li>Numerical errors (discretization, truncation, round-off)</li>
			</ul>
		</div>

		<h3>Stochastic error</h3>
		<div>
			Everything's fine, you just got unlucky.
		</div>
	</div>
	
	<h3>My model used to be right; why is it wrong now?</h3>
	<div>
		* It was overfit.
		* The population has changed ("Concept drift")
		* Your analysis environment has changed ("Data drift")
		<div class="accordion">
		<h3>What causes data drift?</h3>
		<div>
			<ul><li>Structural drift: the source schema is changed</li>
			<li>Semantic drift: the data is constant but its meaning changes.</li>
			<li>Infrastructure drift: breaking change in an update to some part of pipeline.</li>
			</ul>
		</div>
		</div>
	</div>

	<h3>Why is data uncertain?</h3>
	<div>
		<ul>
		<li>It is always incomplete (small samples, few features, physical limits)</li>
		<li>It is usually indirect (proxies, latency)</li>
		<li>It is noisy (measurement error, data corruption, unknown processes)
		<li>It has some risk of being fabricated.</li>
		<li>Ambiguous</li>
		</ul>
	<!--<li>High-latency (economic and physical limits to the recency of your data)</li>-->
	<!--<li>Approximate</li>-->
	</div>
	<h3>What's the difference between machine learning and data mining?</h3>
	<div>
	They're not totally well-defined, but when explicitly distinguished: 
	ML is pure statistical learning: hand over input-output pairs and tweak until function is approximated.
	DM is learning for well-understood domains where algorithms can be partially designed.
	</div>
	<h3>What's the difference between inference and prediction?</h3>
	<div>
	In a sense they are not different: to infer (parameters) is to predict what new data will look like, and to predict that repeat experiments will find similar parameters. But conventionally, inference is an attempt to learn the true parameters, to find the actual way that the data were generated, not just an empirically adequate tool that gets the input-output pairs correct enough.
	A better way of thinking about it: inference tries to get exactly how the data are generated, where prediction just wants the data.
	</div>
	<h3>What's the difference between variance and variation?</h3>
	<div>
	</div>
	<h3>Why is machine learning hard?</h3>
	<div>
	</div>
</div>






| Skill			|	As question									|	Typical of
| 
| Domain analysis	|	What does this vague request really mean?	|	Statistician, software dev	
| Data collection	|	What evidence exists? What can I use?		|
| Exploratory analysis |	What is the data like? What jumps out?	|
| Tool choice		|	What software suits this task best?			|
| Metric choice	|	How will we judge success?					|
| Feature selection |	Which parts are useful?						|
| Data cleaning	|	How to remove flawed data?					|
| Data wrangling	|	How to transform data?						|
| Modelling		|	What structure will answer the question?	|
| Evaluation		|	How good is this model? Under conditions?	|
| Deployment		|	How will this be used? Who will use it?		|
| Communication	|	What result?								|


<iframe src="https://docs.google.com/spreadsheets/d/1udu2AQuHDr7oP3E-bHkzBhyhSOZ7Y9UXKSzQqsvtZpI/pubhtml?gid=0&amp;single=true&amp;widget=true&amp;headers=false"></iframe>



[Snot]: 		http://www.starling-software.com/employment/programmer-competency-matrix.html 