---
layout:     post
title:      "Reversals in academic psychology"
baselink:   /psych
permalink:  /psych
date:       2020-01-25
author:     Gavin   
img:        /img/rev.jpg

visible:    1
published:  true

summary:    List of spurious or exaggerated psychological phenomena
confidence: High that I'm representing the current evidence well, low that all of these will stay reversed.
importance: 6
warnings: 	I am not a social scientist.
count:      1500
---

{%  include psy/links.md   %}


A <a href="{{med}}">medical reversal</a> is when an existing treatment is found to actually be useless or harmful. Psychology has in recent years been racking up reversals: in fact only <a href="{{many}}">40-65%</a> of its classic social results were replicated, in the weakest sense of finding 'significant' results in the same direction. (The average effect found was <a href="{{halv}}">half</a> the originally reported effect.) Such errors are obviously far less costly to society than medical errors, but it's still a form of pollution, so here's the cleanup.<br>

Psychology is not alone: <a href="{{ioan}}">medicine</a>, <a href="{{canc}}">cancer biology</a>, and <a href="{{ec}}">economics</a> all have many irreplicable results, and so do most other fields, as we'd know if they ran replication efforts this large. (<a href="{{whyPsy}}">One reason</a> psychology reversals are so prominent is that it's an unusually 'open' field in terms of code and data sharing. A less scientific field would never have caught its own bullshit.)<br>

<div class="accordion">
	<h3>Selection criteria</h3>
	<div>
		I include a claim if there was at least one of: several failed replications, several good meta-analyses with notably smaller, clear fatal errors in the analysis, a formal retraction, or clear fraud. <br><br>
<!--  -->
		I also include cases like <a href="{{dw}}">growth mindset</a>, where the eventual effect size, though positive, was a tiny fraction of the hyped original claim.<br><br>
<!--  -->
		Thousands of bad papers are published every year, and catching them all would be a full-time job even if they were all included in systematic replication or reanalysis projects, ripe fruit. My rule is that if I hear a spurious effect discussed, or see it in a book, or if it could hurt someone, it's noteworthy.
	</div>
	<h3>Why trust replications more than originals?</h3>
	<div>
		Near-universal rates of <a href="{{preg}}">pre-registration</a> and higher rates of code and data sharing.<br><br>
<!--  -->
		But I don't trust any of them. I look for 3+ failed replications from different labs, just to save me lots of rewriting, as the garden of forking paths and the mystery of the lefty p-curve unfold. 
	</div>
	<!--  -->
	<h3>TODO</h3>
	<div>
		{%  include psy/todo.md   %}
	</div>
</div><br>


The following are empirical findings about empirical findings; they're all open to re-reversal. Also it's not that "we know these claims are false": failed replications (or proofs of fraud) just challenge the evidence for a hypothesis, rather than affirm the opposite. I've tried to report the best-guess effect size after replication rather than play the bad old Yes/No science game. 

<!-- (The polite convention in psychology seems to be to not mention the original effect size.) -->

<br>

---

<br>

## Social psychology 

* No good evidence for <a href="{{wreck}}">many forms of 'priming', automatic behaviour change from 'related' stimuli.</a><br><br>
  * <a href="{{elder1}}">Several</a> <a href="{{ces}}">independent</a> <a href="{{pash}}">null</a> results for elderly priming (Bargh), that hearing about old age makes people walk slower. <a href="{{lakens}}">P-curve alone</a> argues against the first 20 years of studies. 
  * <a href="{{prof}}">No good evidence</a> for professor priming, improved ("+13%") performance at trivia after picturing yourself as a professor vs as a thug.
  * No good evidence for the Macbeth effect, that moral aspersions induce literal physical hygiene. Original <a href="{{g}}">g</a> = 0.7, meta-analysis <a href="{{mac}}">g = 0.07</a>, CI includes 0.
  * Money priming
  * (Importantly, semantic priming is still solid, but the <a href="{{sem}}">effect lasts only seconds</a>.)<br><br>

* <a href="{{zim}}">No good evidence</a> of anything from the Stanford prison experiment (Zimbardo). Not an experiment; demand characteristics and scripting of abuse; constant experimenter intervention; faked reactions from participants; n=24.

* <a href="{{milg}}">No good evidence</a> that "65%" of people will inflict pain if ordered to (Milgram). Experiment riddled with researcher degrees of freedom, implausible agreement between very different treatments, "only half of the people who undertook the experiment fully believed it was real and of those, 66% disobeyed the experimenter." So upper bound around 16% and no strong warrant for that.

<!-- * No good evidence for the broken windows theory (Keizer)
https://sci-hub.tw/10.1177/1368430213502557
https://www.sciencedirect.com/science/article/abs/pii/S027795361830649X
 -->

* Excessive screen-time is <a href="{{potato}}">not strongly associated</a> with low wellbeing; it explains about as much of teen sadness as eating potatoes, 0.4%.

* No good evidence that female-named hurricanes are <a href="{{himmi}}">more deadly</a> than male-named ones. Original effect size was a 274% increase in deaths, driven entirely by four outliers; reanalysis using the full historical dataset found a nonsignificant decrease, p=0.252 (Atlantic) or p=0.553 (Pacific).


* At most weak evidence for implicit bias testing for racism. Implicit bias scores <a href="{{oswald}}">poorly predict</a> actual bias, r = <a href="{{linnae}}">0.15</a>. Also, <a href="{{oswald}}">CIs overlap r=0</a> for the Stereotype IAT. The operationalisations used to measure that predictive power are <a href="{{criterion}}">often unrelated to actual discrimination</a> (e.g. ambiguous brain activations). Test-retest reliability of <a href="{{ret}}">0.44</a> for race, which is usually classed as "unacceptable".

* The Pygmalion effect, that a teacher's expectations about a student affects their performance, is at most <a href="{{jussim}}">small, temporary, and inconsistent</a>, r=0.1 with a reset after weeks. Rosenthal's original claims about massive IQ gains are straightforwardly false. "90%–95% of the time, students are unaffected by teacher expectations".

* At most <a href="{{maths1}}">weak</a> <a href="{{maths2}}">evidence</a> for stereotype threat suppressing girls' maths scores. (Effect d<0.2, and CI includes 0 when publication bias is factored in.)

<!-- * The Asch conformity effect was quite small; only 25% of participants ever gave in -->

* Be very suspicious of anything by Diederik Stapel. <a href="{{stapIt}}">58 retractions here</a>.

<br>

## Positive psychology

* No good evidence that taking a "power pose" lowers cortisol, raises testosterone, risk tolerance, etc. Original effect size said to be d=0.6 for risk-taking, for cortisol d=0.85, for testosterone d=0.66. <a href="{{ronay}}">4</a> <a href="{{ranehill}}">independent</a> <a href="{{garrison}}">replications</a> <a href="{{peerj}}">suggest</a> risk-taking d = [−0.176], testosterone d=[−0.200, 0.121, -0.19], cortisol d = [−0.028, 0.034, 0.22] all CI overlapping 0. <a href="{{crede}}">At most weak evidence</a> for decreased "feelings of power" from contractive posture.<br><br>
* <a href="{{wagen}}">No good evidence</a> for facial-feedback (that smiling causes good mood and pouting bad mood, Strack). Original effect 0.82 out of 10. In 17 replications, effect was 0.03 out of 10, CI overlapping 0.<br><br>
* <a href="{{blue}}">No good evidence</a> for Blue Monday, that the third week in January is the peak of depression or low affect 'as measured by a simple mathematical formula developed on behalf of Sky Travel'. You'd need a huge sample size, in the thousands, to detect the effect reliably and this has never been done.

<br>

## Cognitive psychology

* <a href="{{many2}}">No good evidence</a> for ego depletion, that making decisions suffers muscle-like fatigue. (Baumeister) Previously said to be a large effect (d>0.7), 23 independent replications came out as d = 0.04, 95% CI [−0.07, 0.15]. 

* At best <a href="{{hungry}}">questionable</a> <a href="{{hung}}">evidence</a> for the "<a href="{{jud}}">hungry judge</a>" effect, of massively reduced acquittals (d=2) just before lunch. Explanation involved ego depletion; case order isn't independent of acquittal probability; effect size is implausible on priors.

* <a href="{{water}}">No good evidence</a> for multiple intelligences (in the sense of statistically independent components of cognition). <a href="{{gard}}">Gardner</a>, the inventor: "<i>Nor, indeed, have I carried out experiments designed to test the theory... I readily admit that the theory is no longer current. Several fields of knowledge have advanced significantly since the early 1980s.</i>"


* <a href="{{merby}}">At most</a> weak evidence for brain training (that is, "far transfer" from daily training games to fluid intelligence) in general, in particular from <a href="{{dnb}}">Dual n-Back</a> (d=0.14 [-0.0292  0.3085]). <a href="{{lamp}}">Maybe</a> some effect on non-Gf skills of the elderly.

* In general you should be highly suspicious of anything that claims a positive permanent effect on adult IQ, and even in children the max is <a href="{{give}}">4</a>-<a href="{{iod}}">15 points</a> for a profoundly powerful single intervention (iodine supplementation during pregnancy in deficient populations).

<br>

## Developmental psychology

* Good evidence of a tiny effect of growth mindset (thinking that skill is improveable) on attainment (Dweck). <a href="{{growth}}">A huge meta-analysis</a> found a small effect ("d=0.08", or an increase in scores of less than one-tenth of a standard deviation, in the _most_ effective subpopulation). Original claims ranged up to <a href="{{dwee}}">d=0.95</a>.<br><br>
* At most weak evidence for the Marshmallow effect, that ability to delay gratification as a 4 year old predicts life outcomes at 15 (Mischel). Original effect size was r=0.42 to 0.57 with the SAT, n=68, all children of Stanford academics or friends. Watts et al replication was n=918, r=0.28. After controls, the effect is r=0.05 or <a href="{{marsh}}">d=0.1</a> one-tenth of a standard deviation for an additional minute delay, nonsignificant p-values.<br><br>
<!-- * Perry preschool -->
* "Expertise after 10,000 hours practice" (Gladwell). <a href="{{ericsson}}">Disowned by the supposed proponents</a>.<br><br>
<!-- * Attachment style stability -->
* <a href="{{style}}">No good evidence that tailoring teaching to students' preferred learning styles has any effect on outcomes.


<br>

## Personality psychology

* Pretty good. <a href="{{soto}}">One lab's systematic replications</a> found that effect sizes shrank by 20% though.

* Anything by Hans Eysenck should be considered suspect, but in particular these <a href="{{ey}}">26 'unsafe' papers</a> (including the one which says that reading prevents cancer).

<br>

## Marketing

* <a href="{{wansink}}">Brian Wansink</a> admitted malpractice and fatal errors were found in 50 papers. These include results about portion size and satiety.

<br>

## Neuroscience

* No good evidence that brains contain multiple minds, for instance one per hemisphere. The corpus callosotomy studies which purported to show "two consciousnesses" inhabiting the same brain <a href="{{pinto}}">were badly overinterpreted</a>.

* Readiness potentials <a href="{{libet}}">seem to be actually causal</a>, not diagnostic. So Libet's studies also do not show what they purport to. We still don't have free will (since random circuit noise can tip us when the evidence is weak), but in a different way.

* <a href="{{brain}}">No good evidence</a> for left/right hemisphere dominance correlating with personality differences. No clear hemisphere dominance at all in <a href="{{hem}}">this study</a>.

<!-- * Sex addiction -->

<br>

## Psychiatry

* At most <a href="{{rosenhan}}">extremely weak evidence</a> that psychiatric hospitals (of the 1970s) could not detect sane patients in the absence of deception.

<!-- * Repressed memories / Recovered memory therapy -->


<br>

## Parapsychology

* <a href="{{bem}}">No good evidence</a> for precognition, undergraduates improving memory test performance by studying after the test. Original d=[0.2, 0.4]. This one is fun because Bem's statistical methods were "impeccable" in the sense that they were what everyone else was using. He is Patient Zero in the replication crisis, and has done us all a great service.

<br>

## Evolutionary psychology

* <a href="{{gla}}">No good evidence</a> for the dual mating-strategy hypothesis (that "heterosexual women show stronger preferences for uncommitted sexual relationships... during the high-fertility ovulatory phase of the menstrual cycle, while preferring long-term relationships at other points").

* No good evidence that large parents have more sons (Kanazawa); original analysis makes several errors and <a href="{{denny}}">reanalysis shows near-zero effect</a>. (Original effect size: 8% more likely.)

* No good evidence that men's biceps size predicts opposition to wealth redistribution. <a href="{{arms}}">Measurement was of arm circumference in students</a>, and effect disappears when participant age is included. (Petersen et al)

<!-- * The Fluctuating Female Vote -->
<!-- "Women Are More Likely to Wear Red or Pink at Peak Fertility" -->

<br>

## Behavioural genetics

* <a href="{{ssc}}">No good evidence</a> that 5-HTTLPR is strongly linked to depression, insomnia, PTSD, anxiety, and more.<br>

* Be very suspicious of any such "candidate gene" finding (post-hoc data mining showing large >1% contributions from a single allel). <a href="{{depres}}">0/18</a> replications in candidate genes for depression. <a href="{{psychiatry}}">73% of candidates</a> failed to replicate in psychiatry in general. <a href="{{jbg}}">One big journal</a> won't publish them anymore without replication attempts. <a href="{{gwas}}">A huge GWAS</a>, n=1 million: "We find no evidence of enrichment for genes previously hypothesized to relate to risk tolerance."

<!-- * No strong evidence for the MAOA warrior gene. -->


<br>

<div class="accordion">
	<h3>Mandatory errata</h3>
	<div>
		Some popular books with uncritical treatments of the above<br><br>
<!--  -->
		<ul>
			<li><i>Outliers</i> by Malcolm Gladwell<br>
			founded on the 10,000 hours for mastery claim.</li><br>
			<!--  -->
			<li><i>Behave</i> by Robert Sapolsky<br>
			Himmicanes, power pose, facial feedback, ego depletion, Implicit Association, stereotype threat, broken windows theory, Macbeth effect.</li><br>
			<!--  -->
			<li><i>Thinking, Fast and Slow</i> by Daniel Kahneman<br>
			Entire chapter on all kinds of priming. Facial-feedback, Effects of Head-Movements on Persuasion, Location as Prime, Money Priming, Death Priming, Lady Macbeth Effect. Cognitive disfluency. Ego depletion. Wansink. Hungry judges. Denies the "hot hand".</li><br>
			<!--  -->
			<li><i>Nudge</i> by Thaler and Sunstein<br>
			Wansink, Baumeister, Dweck.</li><br>
			<!--  -->
			<li><i>Smarter</i> by Dan Hurley.<br> 
			Dual n-Back and all manner of nonsense nootropics.</li><br>
			<!--  -->
			<li><i>Peter Watts is an Angry Sentient Tumor</i><br>
			A sadly muddled defence of Bem</li><br>
		</ul>
	</div>
</div>


{%  include comments.html %}




