---
layout:     post
title:      "AI alignment & academia"
baselink:   /acais
permalink:  /acais
date:       2020-07-28
author:     Gavin

img:        /img/nonsense.gif
published:  true
visible:    1

summary:    Estimating AI safety work done by academics working in adjacent areas.
quality:    7
categories: effective-altruism, AI, academia
confidence: High that there is a notable contribution, low in the particular estimates. Lots of Fermi estimates.
importance: 9
wordcount:  3300
---

{%	include acais/links.md		%}

A big reason for the EA focus on AI safety is its neglectedness:

> ...less than $50 million per year is devoted to the field of AI safety or work specifically targeting global catastrophic biorisks.  

<a href="{{k08}}">80,000 Hours</a> (2019)

> ...we estimate fewer than 100 people in the world are working on how to make AI safe. 

<a href="{{ai80k}}">80,000 Hours</a> (2017)

> Grand total: $9.09m… [Footnote: this] doesn’t include anyone generally working on verification/control, auditing, transparency, etc. for other reasons.

<a href="{{impacts}}">Seb Farquhar</a> (2018)

> ...what we are doing is less than a pittance. You go to some random city... Along the highway you see all these huge buildings for companies... Maybe they are designing a new publicity campaign for a razor blade. You drive past hundreds of these... Any one of those has more resources than the total that humanity is spending on [AI safety].  

<a href="{{bos}}">Nick Bostrom</a> (2016) 





{%	include comments.html	%}