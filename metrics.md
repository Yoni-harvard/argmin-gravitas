---
layout: 	page
title: 		Metrics
permalink: 	/metrics/
visible:	true
---

{% assign Spieg = "http://www.statslab.cam.ac.uk/Dept/People/Spiegelhalter/davids.html" %}
{% assign GRADE = "http://handbook.cochrane.org/chapter_12/12_2_assessing_the_quality_of_a_body_of_evidence.htm" %}
{% assign Christg = "https://www.robertchristgau.com/xg/bk-cg90/grades-90s.php" %}
{% assign Galef = "https://juliagalef.com/2017/01/06/a-taxonomy-of-books-that-change-your-worldview/" %}
{% assign MyReading =	"https://docs.google.com/spreadsheets/d/1qPIKI3TO5MpKtyg9DzsK6TOo6NhjHAHZbv3iS2yxnSo/edit?usp=sharing" %}



I use the following scales for the quality of things:
<a name="spiegel-quality"></a>

<div class="accordion">
	<h3>Spiegelhalter on an estimate's quality</h3>
	<div><a href="{{Spieg}}">David Spiegelhalter</a> has a nice rule of thumb for how much to trust estimates:<br>
	<br><ul>
	<li><b>4* : <i>numbers we can believe</i></b>
		<div><blockquote>so accurate than we can, to all intents and purposes, treat them as true</blockquote>.</div>
	</li>
	<li>
		<b>3* : <i>numbers that are reasonably accurate</i></b>
		<div><blockquote>the figure is probably accurate within a relative ±25%: a claimed proportion of 12% could actually be anywhere between 9% and 15%</blockquote>.</div>
	</li>
	<li>
		<b>2* : <i>numbers that could be a long way out</i></b>
		<div><blockquote>Could be anywhere between half and double the given figure. (Proportions should be changed to odds before doubling.)</blockquote></div>
	</li>
	<li>
		<b>1* : <i>numbers that are unreliable</i></b>
		<div><blockquote>the true figure might be more than double or half what is claimed.<br>
		(On the odds scale, for proportions.)</blockquote></div>
	</li>
	<li>
		<b>0* : <i>numbers that were just made up</i></b>
		<div><blockquote>Not evidence; negative information. Even odds of having the correct sign.</blockquote></div>
	</li>
	</ul><br>
	(Obviously for some things - pharmacology and space travel come to mind - anything but 4* is unacceptably poor.)
	<a name="cochrane-quality"></a>
	</div>


	<h3>Cochrane on evidence quality</h3>
	<div>For serious work I use the Cochrane Collaboration's <a href="{{GRADE}}">GRADE scale</a>:<br><br>
		<ul><li>GRADE ⊕⊕⊕⊕ : As good as a well-run randomized trial.</li>
		<li>GRADE ⊕⊕⊕ : As good as a downgraded randomized trial; or an upgraded observational study.</li>
		<li>GRADE ⊕⊕ : As good as an observational study (or a double-downgraded randomized trial).</li>
		<li>GRADE ⊕ : As good as case reports (or triple-downgraded randomized trials...</li>
		</ul><br>
	<a name="confidence"></a>
	</div>


	<h3>Spiegelhalter on confidence in result </h3>
	<div><br>
		<ul>
		<li>95%: "We understand the underlying process. Although we cannot predict what is going to happen, we can provide good numerical assessments."</li>

		<li>80%: "We are reasonably confident in our analysis. We can expect numbers to change as we learn more, but not sufficient to justify major policy shifts."</li>

		<li>60%: "New evidence could have a substantial impact on our assessment, although no major new surprises are expected. We encourage a robust decision-making approach with some precaution and adaptivity."</li>

		<li>20%: "We have a very limited understanding of the process or possibilities. Resilience to unexpected occurrences is called for."</li>
		</ul>
	</div>

	<h3><i>The Inference Review</i> on common academic flaws</h3>
	<div>
		<i><a href="http://inference-review.com/article/the-mother-lode">Inadequacies</a></i> is a catalogue of silly statements by scientists or journalists. It's sort of their gag page. Entries fall into at least one of:<br><br>

		<ul>
    		<li>Exaggeration (E)</li>
    		<li>Irreproducible results (IR)</li>
    		<li>Inadequate data (ID)</li>
    		<li>Begging the question (BQ)</li>
    		<li>Confusing correlation with causation (CCC)</li>
    		<li>Plagiarism (P)</li>
    		<li>Ill-conceived experiments (ICE)</li>
    		<li>Ill-defined concepts (IDC)</li>
    		<li>Conflicts of interest (CI)</li>
    		<li>Scientists behaving badly (SBB)</li>
    		<li>The numbers don’t add up (2 + 2 = 5)</li>
    		<li>Purely ornamental mathematics (POM)</li>
    		<li>Appalling prose (AP)</li>
    		<li>Why did someone publish this? (WDSPT)</li>
    		<li>Just plain dumb (JPD)</li>
    		<li>Don’t touch our funding (DTF)</li>
    		<li>We told you so (WTYS)</li>
    		<li>Too close to call (TCC)</li>
    		<li>Could be (CB)</li>
    		<li>Stating the Obvious (SO)</li>
    		<li>All of the Above (AA)</li>
		</ul><br>
	</div>

	<h3>Christgau on the universality of artworks </h3>
	<div>
		One way an artwork can be important is if it is universal: is its quality obvious even to people who aren't into that sort of thing? Robert Christgau's complicated <a href="{{Christg}}">album rating scale</a> has this at its apex, but also gives "Honourable Mention" credit conditional on the listener being open to that album's particular aesthetic - brilliant:<br><br>
		<ul>	
	 		<li><blockquote>An A+ is a record of sustained beauty, power, insight, groove, and/or googlefritz that has invited and repaid repeated listenings in the daily life of someone with 500 other CDs to get to.</blockquote></li><br>

			<li><blockquote>An A is a record that rarely flags for more than two or three tracks. Not every listener will feel what it's trying to do, but anyone with ears will agree that it's doing it.</blockquote></li><br>

			<li><blockquote>An A- is the kind of garden-variety good record that is the great luxury of musical micromarketing and overproduction. Anyone open to its aesthetic will enjoy more than half its tracks.</blockquote></li><br>

			<li><blockquote>A B+ is remarkable one way or another, yet also flirts with the humdrum or the half-assed.</blockquote></li><br>

			<li><blockquote>A *** Honorable Mention is an enjoyable effort consumers attuned to its overriding aesthetic or individual vision may well treasure.</blockquote></li><br>

			<li><blockquote>A ** Honorable Mention is an likable effort consumers attuned to its overriding aesthetic or individual vision may well enjoy.</blockquote></li><br>

			<li><blockquote>A * Honorable Mention is a worthy effort consumers attuned to its overriding aesthetic or individual vision may well like.</blockquote></li><br>

			<li><blockquote>A Neither (Neither) may impress once or twice with consistent craft or an arresting track or two. Then it won't...</blockquote></li>
		</ul>
	</div>


	<h3>Galef on book impacts  </h3>
	<div>
		Julia Galef has <a href="{{Galef}}">a neat taxonomy</a> of ways that books can affect your worldview. Her model is that a book can <br><br>
		<ol>
		<li>offer you new Data, or </li>
		<li>Theories to explain data, or </li>
		<li>arguments or scenes aimed at taking on particular Values, or </li>
		<li>an entire Thinking style. </li>
		</ol><br>

		She also assigns a number 1-5, roughly "Most Concrete -> Most General" for each type.
	</div>


	<h3>Leech on book durability</h3>
	<div>I approximate a book's value by guessing how often I'll reread it. This rewards dense books, sure, but also ones with broad and complex messages, durability, appeal to people of different ages, and also just the pleasure and beauty of them. I think most books are not worth the time and a small number (< 8% in <a href="{{MyReading}}">a highly selected sample</a>) are worth more than one reading.<br>

	<ul>
		<li>1/5: Not worth one reading.</li>
		<li>2/5: One read maybe, if you're into the topic.</li>
		<li>3/5: Worth one skim.</li>
		<li>3*/5: Great fun, one read. 'Mind candy'.</li>
		<li>4/5: Very good. but one read will do.</li>
		<li>5?/5: Amazing. Will reread.</li>
		<li>5/5: Have reread and expect to do so indefinitely. A companion.</li>
	</ul>
	</div>
</div>

